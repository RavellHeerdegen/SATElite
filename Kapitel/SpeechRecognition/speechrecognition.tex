\subsection{Spracherkennung}
Speech recognition, auch automatic speech recognition (ASR) genannt, macht es Maschinen möglich, Sprache in Text oder Kommandos zu übersetzen. Dies geschieht sowohl durch Identifikation als auch durch Verstehen der eingegebenen Sprachsignale. Die Sprachsignale werden auf erlernte Muster angewendet, wobei Merkmale entnommen werden, um die Signale zuordnen zu können. Das Ziel ist, die menschliche Sprache zu verstehen, um mit dem Menschen kommunizieren zu können.\cite{technology}\\

\subsubsection{Spracherkennung und convolutional neural networks}
In \cite{usingcnn} beschreibt Du Guiming et. al. einen Versuch, bei dem Speech recognition in Verbindung mit einem CNN getestet wird. Die dafür verwendeten Trainingsdaten stammen von 30 Personen. Für die automatische Erkennung der Sprachsignale und ihrer Tonhöhen wird der Mel Frequency Cepstral Coefficient (MFCC) \cite{MFCC} eingesetzt, welcher das Frequenzspektrum kompakt darstellen kann. Für die Merkmalentnahme kommen hamming windows zum Einsatz. Mit dieser Technik können Signale gefiltert und Varianzen geglättet werden, bevor sie das neuronale Netz erreichen. Nach der Verarbeitung der Signale, wird das neuronale Netz mit fünf Personen getestet. Beim ersten Durchlauf der Signale durch das neuronale Netz, sind die erwarteten und vorhergesehenen Werte alle gleich. Der Unterschied zwischen erwarteten und echten Werten wird als cost function bezeichnet. Ist die cost function niedrig, sind die Parameter hochwertiger. Es zeigt sich, dass mit steigender Durchlaufzahl die cost function niedriger wird. Somit kann bestätigt werden, dass sich CNNs sowohl für die Erkennung von isolierten Wörtern eignen, als auch für die Reduzierung von Varianzen.\cite{usingcnn}\\
\\
Rafael M. Santos et. al. zeigen in \cite{noisycnn} auf, wie sich ein CNN in einer geräuschvollen Umgebung verhält. Da sich die sogenannten shared weights in einem CNN über den gesamten Eingaberaum erstrecken, können Merkmale selbst dann gefunden werden, wenn sie sich aufgrund von Störungen z.B. durch Lautstärke an unterschiedlichen Positionen befinden. In dem Experiment wird das CNN so trainiert, dass es die HMM-Verteilungswahrscheinlichkeit schätzen kann. Außerdem klassifiziert das CNN nicht nur die aktuelle Aufnahme, sondern bezieht vorherige und nachkommende Aufnahmen mit ein, um Zusammenhänge zwischen den Informationen herstellen zu können. Als Eingabe werden einzelne Wörter mit ansteigender Lautstärke eingesetzt. Die Eingabedaten bestehen aus brasilianischen und portugiesischen Wörtern, welche zehn mal von jeweils sechs Männern und zwei Frauen vorgetragen wurden. Die Aufnahmen wurden in einer unkontrollierten Umgebung mit einem Mobiltelefon aufgezeichnet, von welchem 8000 Samples in der Sekunde entnommen wurden. Bei dem Versuch hat sich ergeben, dass die Kombination von CNN und HMM, sowohl feature extraction als auch signal detection mit großem Erfolg durchführt. Auch wurde herausgefunden, dass sich die Kombination CNN-HMM am wenigsten von Lautstärke und Geräuschen beeinflussen lässt, im Vergleich zu anderen getesteten Kombinationen wie GMM \cite{svmgmm} oder SVM \cite{svmgmm} in Verbindung mit HMM.

\subsubsection{Spracherkennung und residual neural networks}
In der Studie \cite{residualnn} wurde ein Resnet mit mehreren Res in Kombination mit Speech recognition getestet. Es hat sich zunächst herausgestellt, dass mit einer Anzahl von acht Res, welche hintereinander geschaltet werden, die beste Performanz in Bezug auf die word error rate (WER) erreicht wird. Ab einem Wert von mehr als acht Res, hat die Performanz abgenommen. Verglichen wurde das sogenannte 8Res dabei mit einem 8-DNN, welches aus sechs hidden-layers bestand. Dabei hat sich ergeben, dass das 8Res bessere Ergebnisse als das 8-DNN erzielt. Auch wird aufgezeigt, wie sich wide residual networks (WResnets) auf die Validierung von Daten auswirkt. Wurde die Anzahl der Layer im getesteten Resnet von vier auf zehn erhöht, wurde eine noch bessere Performanz erreicht. Ab einem Wert von zwölf nahm die Performanz wiederum ab, da die Neuronen ab diesem Wert überangepasst waren. Schließlich wurde festgestellt, dass HMM-Resnets mit steigender Anzahl an Res und Layern eine um 0,4\% bessere Performanz als ein HMM-DNN \cite{residualnn} wie z.B. CNN mit HMM in Bezug auf die WER erreichten.


