@article{technology,
abstract = {As a cross-disciplinary, speech recognition is based on the voice as the research object. Speech recognition allows the machine to turn the speech signal into text or commands through the process of identification and understanding, and also makes the function of natural voice communication. Speech recognition involves many fields of physiology, psychology, linguistics, computer science and signal processing, and is even related to the person's body language, and its ultimate goal is to achieve natural language communication between man and machine. The speech recognition technology is gradually becoming the key technology of the IT man-machine interface[1].The paper describes the development of speech recognition technology and its basic principles, methods, reviewed the classification of speech recognition systems and voice recognition technology, analyzed the problems faced by the speech recognition.},
author = {Meng, Jianliang and Zhang, Junwei and Zhao, Haoquan},
doi = {10.1109/ICCIS.2012.202},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/Overview of the speech recognition technology.pdf:pdf},
isbn = {9780769547893},
issn = {07452624},
journal = {Proceedings - 4th International Conference on Computational and Information Sciences, ICCIS 2012,},
keywords = {application,basic,principles- method,speech recognition},
mendeley-groups = {SpeechRecognition},
pages = {199--202},
title = {{Overview of the speech recognition technology}},
year = {2012}
}

@article{usingcnn,
abstract = {Speech recognition, as the man-machine interface, plays a very important role in the field of artificial intelligence. Traditional speech recognition methods are shallow learning structure, and have their limitations. This paper uses the Convolution Neural Networks (CNNs) to realize speech recognition. It is an alternative type of neural network that can reduce spectral variation and model spectral correlations which exist in signals. Besides the paper uses Back Propagation to train the neural network. During the whole experiment, the paper uses a group of speech that recorded by ourselves as training data, and it uses the others to test the neural network. Experimental results show that CNNs can efficiently implement isolated word recognition. {\textcopyright} 2016 IEEE.},
author = {Guiming, Du and Xia, Wang and Guangyan, Wang and Yan, Zhang and Dan, Li},
doi = {10.1109/SIPROCESS.2016.7888355},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/Speech Recognition Based on Convolutional Neural Networks.pdf:pdf},
isbn = {9781509023769},
issn = {1996756X},
journal = {2016 IEEE International Conference on Signal and Image Processing, ICSIP 2016},
keywords = {Speech recognition,back propagation,convolutional neural network},
mendeley-groups = {SpeechRecognition},
pages = {708--711},
title = {{Speech recognition based on convolutional neural networks}},
year = {2017}
}

@article{noisycnn,
abstract = {Wir schreiben deutsch zzz},
author = {Santos, Rafael M. and Matos, Leonardo N. and Macedo, Hendrik T. and Montalvao, Jugurta},
doi = {10.1109/BRACIS.2015.44},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/Speech recognition in noisy environments with convolutional neural networks.pdf:pdf},
isbn = {9781509000166},
issn = {0041-1345},
journal = {Proceedings - 2015 Brazilian Conference on Intelligent Systems, BRACIS 2015},
keywords = {convolutional neural network,noise robustness,speech recognition},
mendeley-groups = {SpeechRecognition},
pages = {175--179},
title = {{Speech recognition in noisy environments with convolutional neural networks}},
year = {2016}
}

@article{svmgmm,
abstract = {La primera Conferencia Internacional sobre la Promoci{\'{o}}n de la Salud reunida en Ottawa el d{\'{i}}a 21 de noviembre de 1986 emite la presente CARTA dirigida a la consecuci{\'{o}}n del objetivo "Salud para Todos en el a{\~{n}}o 2000." Esta conferencia fue, ante todo, una respuesta a la creciente demanda de una nueva concepci{\'{o}}n de la salud p{\'{u}}blica en el mundo. Si bien las discusiones se centraron en las necesidades de los pa{\'{i}}ses industrializados, se tuvieron tambi{\'{e}}n en cuenta los problemas que ata{\~{n}}en a las dem{\'{a}}s regiones. La conferencia tom{\'{o}} como punto de partida los progresos alcanzados como consecuencia de la Declaraci{\'{o}}n de Alma Ata sobre la atenci{\'{o}}n primaria, el documento "Los Objetivos de la Salud para Todos" de la Organizaci{\'{o}}n Mundial de la Salud, y el debate sobre la acci{\'{o}}n intersectorial para la salud sostenido recientemente en la Asamblea Mundial de la Salud.},
author = {Jayashree, Padmanabhan and Melvin Jose, Johnson and Premkumar},
doi = {10.1080/02564602.2015.1010611},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/Machine Learning in Automatic Speech Recognition A Survey.pdf:pdf},
isbn = {92 4 354135 8},
issn = {09745971},
journal = {IETE Technical Review (Institution of Electronics and Telecommunication Engineers, India)},
keywords = {Automatic speech recognition,Gaussian mixture models,Hidden Markov models,Machine learning,Support vector machines},
mendeley-groups = {SpeechRecognition},
number = {4},
pages = {240--251},
publisher = {Taylor {\&} Francis},
title = {{Machine learning in automatic speech recognition: A survey}},
volume = {32},
year = {2015}
}

@article{hmm,
abstract = {Automatic speech recognition (ASR) is an important topic to be performed by a computer system. This paper presents the use of a hybrid hidden Markov model (HMM) and artificial neural networks (ANNs) for automatic speech recognition. The proposed hybrid system for ASR is to take advantage from the properties of both HMM and ANN, improving flexibility and recognition performance. The hybrid ANN/HMM assumes that the output of an ANN is sent to the HMM for ASR. The architecture relies on a probabilistic interpretation of the ANN outputs. Each output unit of the ANN is trained to perform a non-parametric estimate of the posterior probability of a continuous density HMM state given the acoustic observations. After a brief review of HMM and ANN, the paper reports the theoretical aspects and the performance of the proposed hybrid model. Experimental results are listed to demonstrate the potential of this hybrid model.},
author = {Tang, Xian},
doi = {10.1109/PACCS.2009.138},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/hybrid hidden markov model and artificial neural network for automatic speech recognition.pdf:pdf},
isbn = {9780769536149},
journal = {Proceedings of the 2009 Pacific-Asia Conference on Circuits, Communications and System, PACCS 2009,},
keywords = {Artificial neural networks,Automatic speech recognition,Hidden markov model,Hybrid model},
mendeley-groups = {SpeechRecognition},
pages = {682--685},
title = {{Hybrid hidden markov model and artificial neural network for automatic speech recognition}},
year = {2009}
}

@article{residualnn,
author = {Vydana, Hari Krishna and Vuppala, Anil Kumar},
doi = {10.23919/EUSIPCO.2017.8081266},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/Residual neural networks for speech recognition.pdf:pdf},
isbn = {9780992862671},
journal = {25th European Signal Processing Conference, EUSIPCO 2017},
mendeley-groups = {SpeechRecognition},
pages = {543--547},
title = {{Residual neural networks for speech recognition}}
}

@article{cnnemotionrec,
author = {Huang, Christina},
doi = {10.1109/URTC.2017.8284175},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/Combining Convolutional Neural Networks for Emotion Recognition.pdf:pdf},
isbn = {9781538625347},
issn = {18669964},
journal = {2017 IEEE MIT Undergraduate Research Technology Conference, URTC 2017},
keywords = {emotion recognition,neural networks,support vector machines},
mendeley-groups = {EmotionRecognition},
pages = {1--4},
title = {{Combining convolutional neural networks for emotion recognition}},
year = {2018}
}

@article{eyetrackemotionrec,
abstract = {{\textcopyright} 2015 IEEE.We present an approach for emotion recognition using information of the pupil. In last years, the pupil variables have been used as an assessment of emotional arousal. In this article, we generate signals of pupil size and gaze position monitored during image viewing. The emotions are provoked by visual stimuli of colored images. Those images were taken from the International Affective Picture System which has been the reference for objective emotional assessment based on visual stimuli. For recognising the emotions we use the evolution of the eye tracking data during a window of time. The learning dataset is composed by the evolution of the pupil size and the gaze position, and labels associated to the emotional states. We study two kinds of learning tools based on Neural Networks. We obtain promising empirical results that show the potential of using temporal learning tools for emotion recognition.},
author = {Aracena, Claudio and Basterrech, Sebastian and Snasel, Vaclav and Velasquez, Juan},
doi = {10.1109/SMC.2015.460},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/neural networks for emotion recognition based on eye tracking data.pdf:pdf},
isbn = {9781479986965},
journal = {Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015},
keywords = {Affective Computing,Computer-Human Interaction,Emotion Recognition,Neural Networks,Temporal Learning Problem},
mendeley-groups = {EmotionRecognition},
pages = {2632--2637},
title = {{Neural Networks for Emotion Recognition Based on Eye Tracking Data}},
year = {2016}
}

@article{wildemotionrec,
abstract = {Group emotion recognition in the wild is a challenging problem, due to the unstructured environments in which everyday life pictures are taken. Some of the obstacles for an effective classification are occlusions, variable lighting conditions, and image quality. In this work we present a solution based on a novel combination of deep neural networks and Bayesian classifiers. The neural network works on a bottom-up approach, analyzing emotions expressed by isolated faces. The Bayesian classifier estimates a global emotion integrating top-down features obtained through a scene descriptor. In order to validate the system we tested the framework on the dataset released for the Emotion Recognition in the Wild Challenge 2017. Our method achieved an accuracy of 64.68{\%} on the test set, significantly outperforming the 53.62{\%} competition baseline.},
archivePrefix = {arXiv},
arxivId = {1709.03820},
author = {Surace, Luca and Patacchiola, Massimiliano and S{\"{o}}nmez, Elena Battini and Spataro, William and Cangelosi, Angelo},
doi = {10.1145/3136755.3143015},
eprint = {1709.03820},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/emotion recognition in the wild using deep neural networks and bayesian classifiers.pdf:pdf},
isbn = {9781450355438},
journal = {Proceeding ICMI 2017 Proceedings of the 19th ACM International Conference on Multimodal Interaction Pages 593-597},
keywords = {acm reference format,bayesian net-,deep neural networks,emotiw 2017 challenge,ensemble learning,group emotion recognition,works},
mendeley-groups = {EmotionRecognition},
pages = {593--597},
title = {{Emotion Recognition in the Wild using Deep Neural Networks and Bayesian Classifiers}},
url = {http://arxiv.org/abs/1709.03820},
year = {2017}
}

@article{facialemotionrecusingcnn,
abstract = {The use of machines to perform different tasks is constantly increasing in society. Providing machines with perception can lead them to perform a great variety of tasks; even very complex ones such ...},
author = {Awasthi, Ankit},
doi = {10.1145/2818346.2830593},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/Facial emotion recognition using deep convolutional networks.pdf:pdf},
isbn = {978-1-4503-3912-4},
issn = {2160-7508},
journal = {IEEE 4th International Conference on Knowledge-Based Engineering and Innovation (KBEI) Dec. 22, 2017},
keywords = {c onvolutional n eural,classification,emotion,net-},
mendeley-groups = {EmotionRecognition},
number = {September},
pages = {9--12},
title = {{Facial Emotion Recognition Using Deep Learning}},
volume = {1},
year = {2013}
}

@article{patternrec,
author = {{A. K. Jain} and {Robert P. W. Duin} and {J. Mao}},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/Statistical Pattern Recognition A Review.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis And Machine Intelligence, Vol. 22, No. 1, January 2000},
number = {1},
pages = {4--37},
title = {{Statistical Pattern Recognition: A Review}},
volume = {22},
year = {2000}
}


@book{MFCC,
author = {Li Deng and Dong Yu},
booktitle = {Sadhana},
doi = {10.1007/BF02747521},
file = {:C$\backslash$:/Users/RavellHeerdegen/Documents/Unistoff/SAT/RechercheDokumente/2015{\_}Book{\_}AutomaticSpeechRecognition.pdf:pdf},
journal = {Springer Verlag, 2015},
isbn = {978-1-4613-6624-9},
issn = {02562499},
keywords = {Speech recognition,fifth generation computers,pattern recognition,signal processing,speech understanding},
mendeley-groups = {SpeechRecognition},
pages = {85--120},
pmid = {10575681},
title = {{Automatic speech recognition, Springer Verlag}},
volume = {9},
year = {2015}
}