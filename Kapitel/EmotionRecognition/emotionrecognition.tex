\subsection{Gefühlserkennung}
Emotion recognition (ER) ist ein interdisziplinäres Forschungsgebiet, welches die Bereiche Informatik und Psychologie vereint. Das Erforschen von emotionalen Zuständen ist hilfreich, um menschliche Aktionen zu verstehen, oder um menschliche Faktoren in künstliche Systeme zu integrieren~\cite{eyetrackemotionrec}.
Generell werden Gesichtsausdrücke über die Muskelbewegungen im mensch\-lichen Gesicht geregelt. Die Muskelbewegungen im Gesicht werden auch action units (AUs) genannt. Nachdem ein Gesicht erfasst und isoliert wurde, kann ein System dem Gesicht mithilfe von action units analysis eine Emotion zuordnen~\cite{wildemotionrec}.
\\
\\
Beim Arbeiten im Bereich ER und facial expression recognition, unterscheidet man zwischen sechs generellen, kulturunabhängigen Emotionen, welche 1971 von Ekman und Friesen als universell festgelegt wurden: Wut, Ekel, Angst, Freude, Trauer und Überraschung~\cite{cnnemotionrec}. ER findet aber auch Anwendung in Verbindung mit Sprache und Körpersprache. Mit ER soll die natürliche Kommunikation zwischen Mensch und Maschine hergestellt und verbessert werden. Jedoch auch Gefühlszustände eines Menschen erkannt werden, um anschließend passende Werbung oder zugeschnittene Angebote zu erstellen. Methodisch wird zwischen statischen und dynamischen Verfahren unterschie\-den. Das bedeutet, einerseits mit statischen Bildern zu arbeiten, andererseits mit Sequenzen von Bildern, d.h.~mit Videos~\cite{facialemotionrecusingcnn}.
\\
\subsubsection*{Gefühlserkennung und convolutional neural networks}
In~\cite{facialemotionrecusingcnn} wird ein Versuch mit einem CNN in Verbindung mit automatic facial expression recognition (AFER) beschrieben. Bei dem Versuch wurde das Facial Action Coding System (FACS) verwendet, um die Genauigkeit der Erkennung von Emotionen zu verbessern. Das geschieht aufgrund der Möglichkeit des FACS, die AUs im Gesicht zu erkennen und zu interpretieren. Auch kann mit dem FACS die Intensität einer Emotion definiert werden. Als Trainingsdaten fungierte der Cohn-Kanade (CK+) Datensatz. Dieser besteht aus 123 Individuen, welche verschiedene Folgen von emotionalen Ausdrücken aufgenommen haben. Die daraus entstandenen Bilder wurden auf eine einheitliche Größe skaliert und unscharf gemacht. Zusätzlich kamen Techniken wie z.B.~Rotations- oder Farbkorrekturen zum Einsatz, bevor die Daten in das CNN gegeben wurden. Im ersten convolutional layer des eingesetzten CNN wurden visuelle Merkmale wie Kanten, Lippenformen, Falten, Augen und Augenbrauen extrahiert. Durch die berechneten shared weights zwischen den Schichten im CNN, kann ein hohes oder ein geringes Vorkommen von AUs im output layer festgestellt werden. Durch die Varianz der AUs können unterschiedliche Klassifizierungen von Emotionen festgestellt werden. Ergebnis des Versuches war, dass das trainierte CNN Parallelen zwischen den Emotionen Wut und Neutralität gefunden hat. Auch hat sich ergeben, dass Freude am besten erkannt wurde. Dadurch wurde bestätigt, dass sich CNNs für die Erkennung von Emotionen in einem menschlichen Gesicht eignen.
\\
\\
Das von L. Surace et al.~beschriebene Experiment ~\cite{wildemotionrec} benutzt ebenfalls ein CNN, jedoch mit anderen Techniken. Zum Einsatz kommen zwei Methoden, welche sich für das Erfassen von sogenannten lokalen sowie globalen Informationen eignen.\\
Die bottom-up Methodik eignet sich zum Isolieren von Gesichtern aus Bildern, um diese anschließend in das bereits trainierte CNN als Input einzugeben. Die top-down Methode bezeichnet sich als labeling algorithm. Beim labeling werden Bezeichnungen einer Szene zugeordnet, um den Kontext der Szene zu erfassen.\\Die Bezeichner werden daraufhin in ein bayesian network (BN)~\cite{wildemotionrec} gegeben, welches die Bezeichner verarbeitet, um Beziehungen und Abhängigkeiten zwischen den Begriffen herzustellen. Die verarbeiteten Bezeichner werden als Eingabe in das CNN geleitet. Der output layer des CNN besteht dadurch aus drei Ausgängen, welche die Szene als negativ, positiv oder neutral einordnen. Das bedeutet, dass eine Szene z.B. einen traurigen Kontext haben kann, wodurch eine Vorkategorisierung einer Szene durchgeführt werden kann. Da\-durch kann Zeit eingespart werden, da die Einordnung einer Szene als Traurig, zum Ausschluss von positiven, fröhlichen Bezeichnern führt. Zum Einsatz kommt außerdem die GAF Datenbank, welche eine Abbildung von 6470 Bildern von Personen in unterschiedlichen Szenen darstellt. Diese Menge wurde aufgeteilt auf die Trainings-, Validierungs- und auf die Testdaten. Zusätzlich wurde ein Dropout eingesetzt, um die Überanpassung der Neuronen zu vermeiden. Der Dropout sorgt dafür, dass teilweise shared weights übergangen bzw. gewollt verloren gehen. Letztendlich hat sich ergeben, dass das CNN in Kombination mit einem BN die besten Ergebnisse liefert, im Gegensatz zum Versuch ohne BN bzw.~ohne CNN. Ein weiterer Ausbau des Versuches ist die Aufteilung der Klassifizierungen negativ, positiv und neutral auf drei CNNs. Somit kann jedes CNN auf eine Kategorie von Emotionen spezialisiert werden, um noch bessere Ergebnisse zu erzielen.

